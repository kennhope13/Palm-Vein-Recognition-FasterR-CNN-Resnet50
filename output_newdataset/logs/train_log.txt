epoch | train_loss | val_loss | mAP | mAP@0.3 | precision | recall | f1
EP001 | train_loss=0.2401 | val_loss=0.1806 | mAP=0.5239 | mAP@0.3=1.0000 | P=0.1562 | R=0.5000 | F1=0.2381
EP002 | train_loss=0.1489 | val_loss=0.1456 | mAP=0.6609 | mAP@0.3=1.0000 | P=0.4167 | R=0.5000 | F1=0.4545
EP003 | train_loss=0.1254 | val_loss=0.1325 | mAP=0.6853 | mAP@0.3=1.0000 | P=0.3125 | R=0.5000 | F1=0.3846
EP004 | train_loss=0.1150 | val_loss=0.1221 | mAP=0.7248 | mAP@0.3=1.0000 | P=0.3571 | R=0.5000 | F1=0.4167
EP005 | train_loss=0.1086 | val_loss=0.1188 | mAP=0.7566 | mAP@0.3=1.0000 | P=0.3571 | R=0.5000 | F1=0.4167
EP006 | train_loss=0.1034 | val_loss=0.1147 | mAP=0.8000 | mAP@0.3=1.0000 | P=0.4167 | R=0.5000 | F1=0.4545
EP007 | train_loss=0.0998 | val_loss=0.1174 | mAP=0.7152 | mAP@0.3=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000
EP008 | train_loss=0.0962 | val_loss=0.1178 | mAP=0.7221 | mAP@0.3=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000
EP009 | train_loss=0.0939 | val_loss=0.1175 | mAP=0.7033 | mAP@0.3=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000
EP010 | train_loss=0.0924 | val_loss=0.1189 | mAP=0.7152 | mAP@0.3=1.0000 | P=0.4167 | R=0.5000 | F1=0.4545
EP011 | train_loss=0.0905 | val_loss=0.1120 | mAP=0.7733 | mAP@0.3=1.0000 | P=0.4167 | R=0.5000 | F1=0.4545
EP012 | train_loss=0.0890 | val_loss=0.1101 | mAP=0.7733 | mAP@0.3=1.0000 | P=0.4167 | R=0.5000 | F1=0.4545
EP013 | train_loss=0.0883 | val_loss=0.1076 | mAP=0.7525 | mAP@0.3=1.0000 | P=0.4167 | R=0.5000 | F1=0.4545
EP014 | train_loss=0.0872 | val_loss=0.1131 | mAP=0.7493 | mAP@0.3=1.0000 | P=0.4167 | R=0.5000 | F1=0.4545
EP015 | train_loss=0.0861 | val_loss=0.1076 | mAP=0.7366 | mAP@0.3=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000
EP016 | train_loss=0.0854 | val_loss=0.1082 | mAP=0.7505 | mAP@0.3=1.0000 | P=0.4167 | R=0.5000 | F1=0.4545
EP017 | train_loss=0.0849 | val_loss=0.1101 | mAP=0.7023 | mAP@0.3=1.0000 | P=0.3571 | R=0.5000 | F1=0.4167
EP018 | train_loss=0.0841 | val_loss=0.1074 | mAP=0.7505 | mAP@0.3=1.0000 | P=0.4167 | R=0.5000 | F1=0.4545
EP019 | train_loss=0.0840 | val_loss=0.1053 | mAP=0.7711 | mAP@0.3=1.0000 | P=0.4167 | R=0.5000 | F1=0.4545
EP020 | train_loss=0.0834 | val_loss=0.1100 | mAP=0.7340 | mAP@0.3=1.0000 | P=0.4167 | R=0.5000 | F1=0.4545
EP021 | train_loss=0.0827 | val_loss=0.1056 | mAP=0.7711 | mAP@0.3=1.0000 | P=0.4167 | R=0.5000 | F1=0.4545
EP022 | train_loss=0.0823 | val_loss=0.1064 | mAP=0.7711 | mAP@0.3=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000
EP023 | train_loss=0.0824 | val_loss=0.1057 | mAP=0.7711 | mAP@0.3=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000
EP024 | train_loss=0.0821 | val_loss=0.1040 | mAP=0.7711 | mAP@0.3=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000
EP025 | train_loss=0.0820 | val_loss=0.1083 | mAP=0.7453 | mAP@0.3=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000
EP026 | train_loss=0.0819 | val_loss=0.1078 | mAP=0.7453 | mAP@0.3=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000
EP027 | train_loss=0.0820 | val_loss=0.1054 | mAP=0.7711 | mAP@0.3=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000
EP028 | train_loss=0.0819 | val_loss=0.1054 | mAP=0.7642 | mAP@0.3=1.0000 | P=1.0000 | R=1.0000 | F1=1.0000
EARLY_STOPPING at epoch 29: val_loss did not improve for 5 epochs (patience=5).\n